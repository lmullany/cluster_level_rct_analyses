{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edf00ba-738c-4547-b3da-4c9e1c452dba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Demonstration of imputation of outcomes and covariates, followed by cluster-level analysis\n",
    "Here we extend the previous approaches for cluster-level analyses of RCT data to the situation where we have imputed variables. For the demo we use both outcomes and covariates with missing data, and impute those values using multiple imputation by chained equations (MICE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fdca2-a4b2-40e4-ba36-23a5c6f8c863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set more off\n",
    "clear all\n",
    "capture adopath + \"../ado_files/\"\n",
    "use \"../../source_data_for_git_notebooks/data/baby_level_cluster_rct_data.dta\"\n",
    "frame rename default main_data\n",
    "capture frame copy main_data cluster_level, replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4055a-b57d-4fb3-9725-895fbbbd2494",
   "metadata": {},
   "source": [
    "### Note: \n",
    "For now, we are replacing weight to missing if it is beyond the time frame (i.e. if `weight_time_met!=1`. Then, we will impute all missing weights. Note that this ignores the information contained in those weights that were measured after 72 hours, and one might consider a different approach (see <a href=\"doi: 10.1136/bmjopen-2021-060105\">Hazel, Zeger, Mullany et al, 2022 BMJ Open. 2022 Jul 12;12(7):e060105.</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e9a85-e9e3-49cc-b276-1a8e6226ef51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace weight = . if weight_time_met!=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12121375-df23-4b72-a2c7-a40b15920d9f",
   "metadata": {},
   "source": [
    "Use `mi impute chained` to impute various columns using MICE. Note that we also rename the existing preterm variable and create a (passive) preterm variable from the imputed gest_age columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b0f48-cc0b-43be-be3a-fc6caa172e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local imputations = 20\n",
    "qui {\n",
    "    * make sure not already\n",
    "    capture mi unset\n",
    "    * set data for MI in wide format\n",
    "    mi set wide\n",
    "    * register various columns for imputation\n",
    "    mi register imputed weight sex gest_age bmi mother_height\n",
    "    * set seed for reproducibility\n",
    "    set seed 123\n",
    "    * impute all variables using MICE\n",
    "    mi impute chained (regress) weight gest_age bmi mother_height (logit) sex = mother_age, add(`imputations') replace\n",
    "    * generate preterm from the impute gestage\n",
    "    rename preterm preterm_original\n",
    "    mi passive: generate preterm = gest_age<37\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fa969-90ad-471f-81a1-4d2578132758",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data after imputation\n",
    "Above, we have prepared our dataset for multiple imputation using the `mi` suite of commands.  The first command unsets the data in case it previously has been set. The second command sets our dataset to be ready for `mi` utilities, and indicates that any new columns (i.e. imputed data) should be appended as a new column (i.e. in wide format). We then register the variables that we would like to impute. In this case, we are imputing a combination of outcomes (`weight`, `gestage`) and non-outcomes (`sex`, `bmi`, `mother_height`) and for demonstration purposes, we are also adding a fixed indepedent var (i.e. a non-imputed variable): `mother_age`. For reproducibility, we set the seed (`set seed 123`), and then we run the MICE command, indicating that we want to perform linear regression when the equations includes continous variable, and logistic regression for the binary variables (in this case, `sex`)\n",
    "\n",
    "After imputation, we can see that we have created a new column for each imputation and each imputed variable. For example for `weight` there are  columns `_1_weight, _2_weight, etc` for each imputation, and each of these columns hold values from *both* the original `weight` value and the imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2179516-cc09-4093-b928-53f0d0dc882d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40e539-f962-4542-8e57-a825c078343b",
   "metadata": {},
   "source": [
    "This is what those columns look like when `weight` is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffc5da-eade-45ac-9797-318a48b919ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%head 2 weight _*_w* if weight==."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3085d5b-4d49-46eb-965c-8b13aba9cc69",
   "metadata": {},
   "source": [
    "And of course, when `weight` is not missing, these values are constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447f6f8-9c9c-4e4b-a362-1d58d5b82157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%head 2 weight _*_w* if weight!=."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6d5c7-88f5-4501-8470-29ceaffe6431",
   "metadata": {},
   "source": [
    "## Analysis using multiply imputed datasets\n",
    "\n",
    "The `mi` suite of commands allows for running estimation commands (like `regress`, `logit`, `poisson`, `xtgee`, etc). Therefore, if this were an individually randomized trial, we could estimate the treatment (i.e. ENP) effect on weight using imputed data, by simply doing something like:\n",
    "```stata\n",
    "mi estimate: regress weight facility_trt\n",
    "```\n",
    "\n",
    "Or, we could account for the clustered-randomization but still do an individual-level analysis using `xtgee` or `xtreg`, with or without adjustment, like this:\n",
    "```stata\n",
    "mi estimate: xtreg weight facility_trt sex mother_age mother_height bmi, mle i(cluster)\n",
    "*or \n",
    "mi estimate: xtgee weight facility_trt sex, i(cluster)\n",
    "```\n",
    "\n",
    "However, there is no built-in cluster-level analysis command that can be passed as an estimation command to the `mi estimate: <estimation_command>` api. \n",
    "\n",
    "Therefore, we have two options\n",
    "1. We can manually do the estimation on each of the imputed datasets, and combine the results according to Rubin's rules, perhaps using a user-written ado file to make this combining easier, and more reproducible\n",
    "2. We can wrap our cluster-level analysis approaches in an ado file that has been custom-designed to work with the `mi estimate` api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ea0fc-4759-47f1-98f7-c23904e58f2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manual estimation\n",
    "Below, I demonstrate manual estimation of the effect of `ENP` on `weight` via cluster-level summaries, using multiple imputed datasets. The basic approach is to do the cluster-level analysis separately on each of the N imputed datasets in a loop, each time saving the results (basically the parameter estimate of interest, the standard error, and the degrees of freedom) into a separate accumulating frame, switch to that frame, and run a user-written command that can pool the results.  More specifically, the code below:\n",
    "\n",
    "1. creates a frame (can be temporary, or permanent) to save the results of the each analysis\n",
    "2. initiates a loop using `foreach` to loop through each of the N imputations\n",
    "3. preserves the dataset \n",
    "4. estimates the mean weight for each cluster, using the `_<i>_weight` variable (i.e. we are doing this by imputed dataset)\n",
    "5. does a regression of weight on facility_trt (i.e. equivalent to a t-test)\n",
    "6. posts those results to the accumulating temporary frame\n",
    "7. restores the dataset to return to the next imputed dataset, to repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efe39c-d934-48fc-b9f0-c99910e97a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "capture frame copy main_data cluster_level, replace\n",
    "frame change cluster_level\n",
    "\n",
    "capture frame drop manual_imputation_results\n",
    "\n",
    "\n",
    "frame create manual_imputation_results double(imp beta variance df)\n",
    "\t\n",
    "* Now, loop through each of the imputations\n",
    "quietly {\n",
    "    foreach i of numlist 1/`imputations' {\n",
    "        * we are going to collapse, so we preserve first\n",
    "        preserve\n",
    "        * we regress the mean cluster-level weight on the allocation; this is equivalent\n",
    "        * to doing a t-test\n",
    "        collapse (mean) weight = _`i'_weight, by(facility_trt cluster_label)\n",
    "        regress weight facility_trt\n",
    "        * we post the imputation number, the estimate of the regression, the variance, and the residual\n",
    "        * degrees of freedom to the temporary frame\n",
    "        frame post manual_imputation_results (`i') (`=e(b)[1,1]') (`=e(V)[1,1]') (`=e(df_r)')\n",
    "        * restore back to the non-collapsed version for the next iteration of the analysis\n",
    "        restore\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe61e54-1544-429f-9a08-4d0446ea52b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results from each imputation\n",
    "If we change to this frame, we can see the results that have accumulated (i.e. row-by-row) for each of the `N` imputed datasets. For each imputation, we have an estimate of the difference in cluster-level mean weight across `facility_trt`, and an estimate of the variance, plus the degrees of freedom (which is constant, because each imputation has the same number of clusters and same estimation command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad267c8d-f589-481e-9829-430f903498e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame change manual_imputation_results\n",
    "list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af837e7-1f60-4726-965d-5369e0865bef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How do we pool these? \n",
    "We can pool these following Rubin's Rules. The following ado file (called `\"mi_pooled.ado\"`, and located in the `../ado_files` folder), takes the names of the estimate column, the variance column, and the degrees of freedom column, and returns as set of scalar (`return list`), various values such as the overall estimate and the overall standard error, according to those Rules. We can manually then created CI from those values\n",
    "\n",
    "```stata\n",
    "program define mi_pooled, rclass\n",
    "\tversion 16.1\n",
    "\tsyntax varlist(min=2 max=3 numeric)\n",
    "\ttokenize `varlist'\n",
    "\t\n",
    "\t* summarize the first variable, which is the list of betas\n",
    "\tqui sum `1'\n",
    "\t* the pooled estimate is just mean of the betas\n",
    "\ttempname pe\n",
    "\tscalar `pe' = r(mean)\n",
    "\t* the between imputation variance is the variance of these betas\n",
    "\ttempname bv\n",
    "\tscalar `bv' = r(Var)\n",
    "\t\n",
    "\t* summarize the second variable, which is the list of variances\n",
    "\tqui sum `2'\n",
    "\t* the within imputation variance is the mean of the variances\n",
    "\ttempname wv\n",
    "\tscalar `wv' = r(mean)\n",
    "\t\n",
    "\t* the total variance is the within imputation variance plus the \n",
    "\t* between imputation variance  + the between\n",
    "\t* imputation variance divided by the number of observation)\n",
    "\ttempname tv\n",
    "\tscalar `tv' = `wv' + `bv' + `bv'/`=_N'\n",
    "\t\n",
    "\t* degrees of freedom:\n",
    "\ttempname r\n",
    "\tscalar `r' = (`bv' + `bv'/`=_N')/`wv'\n",
    "\ttempname _df\n",
    "\tscalar `_df' = (`=_N'-1)*(1+1/`r')^2\n",
    "\t\n",
    "\t* \n",
    "\tif \"`3'\"!=\"\" {\n",
    "\t    qui sum `3'\n",
    "\t\ttempname v_complete\n",
    "\t\tscalar `v_complete' = r(min)\n",
    "\t\ttempname gam\n",
    "\t\tscalar `gam'= (1 + 1/`=_N')*`bv'/`tv'\n",
    "\t\ttempname v_obs\n",
    "\t\tscalar `v_obs' = `v_complete'*(`v_complete'+1)*(1-`gam')/(`v_complete' + 3)\n",
    "\t\tscalar `_df' = (1/`_df' + 1/`v_obs')^-1\n",
    "\t}\n",
    "\t\n",
    "\t* return these scalars\n",
    "\treturn scalar b=`pe'\n",
    "\treturn scalar V=`tv'\n",
    "\treturn scalar wv = `wv'\n",
    "\treturn scalar bv = `bv'\n",
    "\treturn scalar m = `=_N'\n",
    "\treturn scalar deg_freedom = `_df'\n",
    "\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4db58-889f-4c75-be6c-4cf0f2de6e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi_pooled beta variance df\n",
    "return list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e0d12-d919-4113-af6c-a31e754d411c",
   "metadata": {},
   "source": [
    "## One can leverage these returned scalars to manually construct a confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5fd3e-8148-4a3c-babb-e72ec657413b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local est = r(b)\n",
    "local se = r(V)^0.5\n",
    "\n",
    "* hard coding an alpha level\n",
    "local level = 95\n",
    "local alpha = (100-`level')/100\n",
    "local lower = `est' - `se'*invt(r(deg_freedom), 1-`alpha'/2)\n",
    "local upper = `est' + `se'*invt(r(deg_freedom), 1-`alpha'/2)\n",
    "di \"Est \" %3.2f `est' \" with `level'% CI: (\" %3.2f `lower' \" , \" %3.2f `upper' \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c9586-aea2-4222-aee5-6df461dab21c",
   "metadata": {},
   "source": [
    "## Better Option: writing our own `mi` compatible estimation command\n",
    "The second option is to try to write an estimation command that is has `properties(mi)` making it compatible with `mi` and thus allowing us to call it using `mi estimate: <our_user-written_command>`. Below is an example of such a command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9d6c5-2cc5-4a4d-8e6d-bbf20b871060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "capture program drop cluster_level_continuous\n",
    "\n",
    "program define cluster_level_continuous, eclass properties(mi)\n",
    "    syntax varlist(min=3 max=3 numeric)\n",
    "    marksample touse\n",
    "    tokenize `varlist'\n",
    "    preserve \n",
    "        collapse (mean) `1', by(`2' `3')\n",
    "        regress `1' `2'\n",
    "        matrix b = e(b)\n",
    "        matrix V = e(V)\n",
    "        local n = _N\n",
    "        local df_m = `n' - 2\n",
    "        local df_r = `n' - 2\n",
    "       \n",
    "    restore\n",
    "    ereturn post b V, esample(`touse')\n",
    "    ereturn local cmd =\"ttest\"\n",
    "    ereturn scalar N = `n'\n",
    "    ereturn local title = \"Continous Outcome, No Adjustment\"\n",
    "    ereturn scalar df_m = `df_m'\n",
    "    ereturn scalar df_r = `df_r'\n",
    "end\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99d70e-fc7a-4ca1-94d1-50b35ddadea8",
   "metadata": {},
   "source": [
    "Once we have our command from above,  we can actually use it along with `mi estimate:`, which handles all of the above. That is, it figures out that `weight` is an imputed variable, and therefore run the `cluster_level_continuous` command once for each of the imputed datasets (like our loop), combines all the estimates together using Rubin's Rules (like our `mi_poooled` command), and uses the combined estimate, the between and within imputation variance, and the degrees of freedom to get a confidence interval (like our leveraging of the scalars returned by `mi_pooled`. Therefore, writing our own mi-compatible command is a better approach\n",
    "\n",
    "<p style='color:red'>Notice that the results show below are equivalent to those obtained through our manual approach</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fe164-e3c0-4535-839c-2e7905b8f1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "capture frame copy main_data cluster_level, replace\n",
    "frame change cluster_level\n",
    "mi estimate: cluster_level_continuous weight facility_trt cluster_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3f93d-dcdf-4b25-bb33-d6eb07aa3968",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generalize the above command\n",
    "Notice that above command only allows the outcome, the treatment variable, and the cluster variable to be passed (therefore, we can't use it for adjusment) and it only works for continous variables. Better if we could write the command in a much more general way so that it can handle a wide variety of questions. \n",
    "\n",
    "Here is one such implementation, and is stored in `ado_files/`\n",
    "``` stata\n",
    "capture program drop cluster_glm\n",
    "\n",
    "program define cluster_glm, eclass properties(mi)\n",
    "    syntax varlist(min=1 numeric), cluster(varname) trt(varname) [family(string),Level(real 95)]\n",
    "    marksample touse\n",
    "    tokenize `varlist'\n",
    "    quietly {\n",
    "        preserve\n",
    "        if \"`family'\" == \"binomial\" {\n",
    "            glm `varlist', family(`family') link(log)\n",
    "            predict prob if e(sample)==1, xb\n",
    "            replace prob = exp(prob)\n",
    "            collapse (sum) expected = prob observed = `1', by(`trt' `cluster')\n",
    "            gen cluster_y = observed/expected          \n",
    "            qui ttest cluster_y, by(`trt') reverse\n",
    "            noi t_test_binary_ci, level(`level')\n",
    "            matrix b = (log(r(mu_1)) - log(r(mu_2))), log(r(mu_2))\n",
    "            matrix colnames b = `trt' _cons\n",
    "            matrix rownames b = y1\n",
    "            scalar V = r(sd_1)^2/(r(N_1)*r(mu_1)^2) + r(sd_2)^2/(r(N_2)*r(mu_2)^2)\n",
    "            scalar consV = r(sd_2)^2/(r(N_2)*r(mu_2)^2)\n",
    "            matrix V = V, consV \\ consV, -1*consV\n",
    "            matrix rownames V = `trt' _cons\n",
    "            matrix colnames V = `trt' _cons\n",
    "            if \"`2'\" == \"\" local title = \"Binary Outcome, No Adjustment\"\n",
    "            else local title = \"Binary Outcome, Adjusted for Covariate(s)\"\n",
    "        } \n",
    "        else {\n",
    "            glm `varlist', family(`family')\n",
    "            predict resid if e(sample), working\n",
    "            collapse (mean) cluster_y = resid, by(`trt' `cluster')\n",
    "            noi regress cluster_y `trt', level(`level')\n",
    "            matrix b = e(b)\n",
    "            matrix V = e(V)\n",
    "            if \"`2'\" == \"\" local title = \"Continuous Outcome, No Adjustment\"\n",
    "            else local title = \"Continuous Outcome, Adjusted for Covariate(s)\"\n",
    "        }\n",
    "        \n",
    "        local n = _N\n",
    "        local df_m = 1\n",
    "        local df_r = `n' - 2\n",
    "        restore\n",
    "    }\n",
    "\n",
    "    ereturn post b V, esample(`touse')\n",
    "    ereturn local cmd =\"glm\"\n",
    "    ereturn scalar N = `n'\n",
    "    ereturn local title = \"`title'\"\n",
    "    ereturn scalar df_m = `df_m'\n",
    "    ereturn scalar df_r = `df_r'\n",
    "\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5994dd-2d56-4748-ae7d-088e6e0125f1",
   "metadata": {},
   "source": [
    "### Example, using generalized function for binary outcome, without adjustment\n",
    "Note: for binary outcome, use `eform` sub-option in `mi estimate`. You can also set the confidence interval directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a515f9-3b07-45a5-8772-a0146d4eaca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi estimate,eform level(95): cluster_glm preterm, cluster(cluster_label) trt(facility_trt) family(\"binomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aabbf76-82d6-4f19-9c6e-ba82b0da021a",
   "metadata": {},
   "source": [
    "### Example, using generalized function for continuous outcome, without adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e341d71-f328-429e-bc7f-4c16f2dbfb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi estimate: cluster_glm weight, cluster(cluster_label) trt(facility_trt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcb052-985b-430b-9370-2c90ed339ec5",
   "metadata": {},
   "source": [
    "### Example, using generalized function for continuous outcome, with adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf15f47-0deb-452a-92d4-e5c40f76f3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mi estimate: cluster_glm weight bmi mother_age gest_age, cluster(cluster_label) trt(facility_trt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd3d7dc-8942-4330-a3a4-0ff414c012c9",
   "metadata": {},
   "source": [
    "<h2 style='color:red'>Note that we can even use this command in non-imputation situations</h2>\n",
    "Compare the following calls to the main unadjusted results in the non-imputation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45381a3a-a872-45c7-9e27-e391248b2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_glm preterm_original, cluster(cluster_label) trt(facility_trt) family(\"binomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e3053-f1a0-4d3c-abf4-43fd0025bea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_glm weight, cluster(cluster_label) trt(facility_trt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata (nbstata)",
   "language": "stata",
   "name": "nbstata"
  },
  "language_info": {
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
